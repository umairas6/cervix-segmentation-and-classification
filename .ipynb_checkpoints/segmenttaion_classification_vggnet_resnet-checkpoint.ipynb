{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# system libraries\n",
    "import os\n",
    "from glob import glob\n",
    "import h5py\n",
    "from time import time\n",
    "\n",
    "# numerical,image and plotting stuff\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import skimage.transform as tf\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = glob('/kaggle/input/intel-mobileodt-cervical-cancer-screening/train/train/*/*')\n",
    "files.sort()\n",
    "df = pd.DataFrame({'fpath':files,'w':0,'h':0})\n",
    "df\n",
    "df['category'] = df.fpath.str.extract('kaggle/input/intel-mobileodt-cervical-cancer-screening/train/train/Type_([0-9]*)/', expand=False).astype(np.int8) # extract class\n",
    "df['category']\n",
    "df['fname'] = df.fpath.str.extract('kaggle/input/intel-mobileodt-cervical-cancer-screening/traintrain/[a-zA-Z0-9_]*/([0-9_.jpg]*)', expand=False) # extract file name\n",
    "df = df.sort_values(['fpath'])\n",
    "df.head()\n",
    "df['fname'] = df.fpath.str.extract('kaggle/input/intel-mobileodt-cervical-cancer-screening/train/train/[a-zA-Z0-9_]*/([0-9_.jpg]*)', expand=False) # extract file name\n",
    "df = df.sort_values(['fpath'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,h,w,ch = len(df),224,224,3\n",
    "\n",
    "# function for resizing an image\n",
    "def read_resize(fpath,h=224,w=224,ch=3):\n",
    "    im = Image.open(fpath)\n",
    "    w_im, h_im = im.size\n",
    "    if w_im < h_im: \n",
    "        mid_h = h_im/2\n",
    "        half_w = w_im/2\n",
    "        bbox = (0,mid_h-half_w,w_im,mid_h+half_w)\n",
    "    else:\n",
    "        print(fpath + ' is wide not long')\n",
    "        mid_w = w_im/2\n",
    "        half_h = h_im/2\n",
    "        bbox = (mid_w-half_h,0,mid_w+half_h,h_im)\n",
    "    im_sml = im.crop(bbox).resize((w,h))\n",
    "    return np.asarray(im_sml)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fpath = df.fpath.iloc[1030]\n",
    "im = read_resize(fpath,h,w,ch)\n",
    "plt.title('sample for cervix type 3')\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = df.fpath.iloc[103]\n",
    "im = read_resize(fpath,h,w,ch)\n",
    "plt.title('sample for cervix type 2')\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = df.fpath.iloc[10]\n",
    "im = read_resize(fpath,h,w,ch)\n",
    "plt.title('sample for cervix type 1')\n",
    "plt.imshow(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,h,w,ch = len(df),224,224,3\n",
    "\n",
    "# function for resizing an image\n",
    "def read_resize(fpath,h=224,w=224,ch=3):\n",
    "    im = Image.open(fpath)\n",
    "    w_im, h_im = im.size\n",
    "    if w_im < h_im: # general case\n",
    "        mid_h = h_im/2\n",
    "        half_w = w_im/2\n",
    "        bbox = (0,mid_h-half_w,w_im,mid_h+half_w)\n",
    "    else:\n",
    "        print(fpath + ' is wide not long')\n",
    "        mid_w = w_im/2\n",
    "        half_h = h_im/2\n",
    "        bbox = (mid_w-half_h,0,mid_w+half_h,h_im)\n",
    "    im_sml = im.crop(bbox).resize((w,h))\n",
    "    return np.asarray(im_sml)\n",
    "\n",
    "# pre-process input for VGG16\n",
    "def scale_pixels(im):\n",
    "    im[:, :, :, 0] -= 103.939\n",
    "    im[:, :, :, 1] -= 116.779\n",
    "    im[:, :, :, 2] -= 123.68\n",
    "    # 'RGB'->'BGR'\n",
    "    im = im[:, :, :, ::-1]\n",
    "    return im\n",
    "\n",
    "\n",
    "def unscale_pixels(im):\n",
    "    # 'BGR'->'RGB'\n",
    "    im = im[:, :, ::-1]\n",
    "    im[:, :, 0] += 103.939\n",
    "    im[:, :, 1] += 116.779\n",
    "    im[:, :, 2] += 123.68\n",
    "    return im\n",
    "\n",
    "# plot a sample cropped and resized image\n",
    "fpath = df.fpath.iloc[0]\n",
    "im = read_resize(fpath,h,w,ch)\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a random set of 15 pictures for each type\n",
    "\n",
    "s = 15 # number of random pictures per type\n",
    "f1 = df[df.category == 1].sample(n=s,random_state=1).fpath\n",
    "f2 = df[df.category == 2].sample(n=s,random_state=1).fpath\n",
    "f3 = df[df.category == 3].sample(n=s,random_state=1).fpath\n",
    "f = pd.concat([f1,f2,f3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brighten(im,factor):\n",
    "    return np.clip(im*factor,a_max=255.,a_min=0.)\n",
    "\n",
    "brightening_factor = 0.8\n",
    "for i in range(len(f)):\n",
    "    if i % 15 == 0:\n",
    "        fig = plt.figure(figsize=(15,8))\n",
    "        type_i = 'Type ' + str(int(i/15+1))\n",
    "        plt.suptitle(type_i)\n",
    "    ax = plt.subplot(3,s/3,(i%15)+1)\n",
    "    im = read_resize(f.iloc[i])\n",
    "    ax.imshow(brighten(im,brightening_factor)/255) # rescale to (0,1) since we have floats now\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import adjust_gamma, adjust_sigmoid, equalize_adapthist\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "# adjust_sigmoid\n",
    "plt.subplot(131)\n",
    "plt.axis('off')\n",
    "plt.title('Adjust Sigmoid')\n",
    "plt.imshow(adjust_sigmoid(im,cutoff=0.5,gain=5)) # feel free to play around with the cutoff and gain\n",
    "\n",
    "# adjust_gamma\n",
    "plt.subplot(132)\n",
    "plt.axis('off')\n",
    "plt.title('Adjust Gamma')\n",
    "plt.imshow(np.clip(adjust_gamma(im/255,gamma=0.8,gain=1.3),a_max=1.,a_min=0.))\n",
    "\n",
    "# equalize_adapthist\n",
    "plt.subplot(133)\n",
    "plt.axis('off')\n",
    "plt.title('Histogram Equalization')\n",
    "plt.imshow(equalize_adapthist(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model feature extractors\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "vgg_none = VGG16(include_top=False, weights='imagenet', input_shape=None, pooling=None)\n",
    "\n",
    "print('vgg_none output_shape: ' + str(vgg_none.output_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "t = time()\n",
    "\n",
    "# read in provided data\n",
    "X = np.zeros((n,h,w,ch))\n",
    "\n",
    "for i in range(len(df)):\n",
    "    fpath = df.fpath.iloc[i]\n",
    "    x = read_resize(fpath,h,w,ch)\n",
    "    X[i,...] = x\n",
    "    \n",
    "    \n",
    "X = scale_pixels(X)\n",
    "print('Reading took %is' % int(time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# outcome labels\n",
    "Y = df['category'].unique()\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%time\n",
    "features_train = vgg_none.predict(X,verbose=1)\n",
    "print(features_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time()\n",
    "\n",
    "\n",
    "submit_img\n",
    "n_test = len(submit_img)\n",
    "X_submit = np.zeros((n_test,h,w,ch))\n",
    "for i in range(n_test):\n",
    "    fpath = submit_img[i]\n",
    "    x = read_resize(fpath,h,w,ch)\n",
    "    X_submit[i,...] = x\n",
    "    if i%100==0:\n",
    "        print('Read %ith image' % i)\n",
    "\n",
    "X_submit = scale_pixels(X_submit)\n",
    "\n",
    "print('Reading took %is' % int(time()-t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "features_submit = vgg_none.predict(X_submit,verbose=1)\n",
    "print(features_submit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug = pd.DataFrame()\n",
    "n_aug = 2000 # number of images to augment to per class\n",
    "\n",
    "for cl in df.category.unique():\n",
    "    \n",
    "    # get number of provided images\n",
    "    n_provided = (df.category == cl).sum()\n",
    "    \n",
    "    # upsample the difference, and append below\n",
    "    category_upsampled = df[df.category == cl].sample(n=n_aug-n_provided,replace=True,random_state=1)\n",
    "    df_aug = pd.concat([df_aug,category_upsampled])\n",
    "\n",
    "print(df_aug.groupby('category').count()) # display number of images to upsample by category\n",
    "print(len(df_aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2 = len(df_aug)\n",
    "\n",
    "# save input image array\n",
    "'''\n",
    "dX_train = f.create_dataset(\"train/img_cropped_resized_scaled\", (n,h,w,ch), dtype='float64')\n",
    "dX_train[...] = X\n",
    "\n",
    "dX_submit = f.create_dataset(\"submit/img_cropped_resized_scaled\", (n_test,h,w,ch), dtype='float64')\n",
    "dX_submit[...] = X_submit\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def augment(img,rng,h=224,w=224):\n",
    "    r_rotate = rng.uniform(-np.pi/6,np.pi/6,1)[0]\n",
    "    tf_rotate = tf.SimilarityTransform(rotation=r_rotate)\n",
    "    tf_scale = tf.SimilarityTransform(scale=rng.uniform(1,1.5,1))\n",
    "    tf_shear = tf.AffineTransform(shear=rng.uniform(-0.1,0.1,1))\n",
    "    tf_shift = tf.SimilarityTransform(translation=[-w/2, -h/2])\n",
    "    tf_shift_inv = tf.SimilarityTransform(translation=[w/2, h/2])\n",
    "    trans = tf_shift + tf_scale + tf_shear + tf_rotate + tf_shift_inv\n",
    "\n",
    "    img_aug = tf.warp(img, trans.inverse)\n",
    "    # randomly flip vertically\n",
    "    if rng.uniform() > 0.5:\n",
    "        img_aug = img_aug[::-1,:,:]\n",
    "    # randomly flip horizontally\n",
    "    if rng.uniform() > 0.5:\n",
    "        img_aug = img_aug[:,::-1,:]\n",
    "\n",
    "    return img_aug\n",
    "\n",
    "# plot with and without augmentation\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.subplot(171)\n",
    "plt.imshow(im)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "for i in range(1,8):\n",
    "    plt.subplot(1,7,i)\n",
    "    plt.imshow(augment(im,np.random.RandomState(i))) # sample augment\n",
    "    plt.title('Augmented')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug = pd.DataFrame()\n",
    "n_aug = 2000 # number of images to augment to per class\n",
    "\n",
    "for cl in df.category.unique():\n",
    "    \n",
    "    # get number of provided images\n",
    "    n_provided = (df.category == cl).sum()\n",
    "    \n",
    "    # upsample the difference, and append below\n",
    "    category_upsampled = df[df.category == cl].sample(n=n_aug-n_provided,replace=True,random_state=1)\n",
    "    df_aug = pd.concat([df_aug,category_upsampled])\n",
    "\n",
    "print(df_aug.groupby('category').count()) # display number of images to upsample by category\n",
    "print(len(df_aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time()\n",
    "\n",
    "X_aug = np.zeros((len(df_aug),h,w,ch))\n",
    "Y_aug = df_aug.category\n",
    "rng = np.random.RandomState(1)\n",
    "for i in range(len(df_aug)):\n",
    "    fpath = df_aug.fpath.iloc[i]\n",
    "    ix = df[df.fpath==fpath].index[0]\n",
    "    x = X[ix,...]\n",
    "    x_aug = augment(x,rng)\n",
    "    X_aug[i,...] = x_aug\n",
    "    if i % 100 == 0:\n",
    "        print('Augmented %ith image' % i)\n",
    "\n",
    "print('Reading took %is' % int(time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "features_train_aug = vgg_none.predict(X_aug,verbose=1)\n",
    "print(features_train_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def convert_file(input_dir, filename, output_dir):\n",
    "    filepath = input_dir + '/' + files\n",
    "    fin = open(filepath, 'rb')\n",
    "    binary_data = fin.read()\n",
    "    new_filepath = output_dir + '/' + filename[:-4] + '.hdf5'\n",
    "    f = h5py.File(new_filepath)\n",
    "    dt = h5py.special_dtype(vlen=np.dtype('uint8'))\n",
    "    dset = f.create_dataset('binary_data', (100, ), dtype=dt)\n",
    "    dset[0] = np.fromstring(binary_data, dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_resize(fpath,rng,h=224,w=224,ch=3):\n",
    "    im = Image.open(fpath)\n",
    "    w_im, h_im = im.size\n",
    "    crop_offset = rng.uniform(low=-20,high=20,size=1)[0]\n",
    "    if w_im < h_im: # general case\n",
    "        mid_h = h_im/2\n",
    "        half_w = w_im/2\n",
    "        bbox = (0,mid_h-half_w+crop_offset,w_im,mid_h+half_w+crop_offset)\n",
    "    else:\n",
    "        logging.debug(fpath + ' is wide not long')\n",
    "        mid_w = w_im/2\n",
    "        half_h = h_im/2\n",
    "        bbox = (mid_w-half_h+crop_offset,0,mid_w+half_h+crop_offset,h_im)\n",
    "    im_sml = im.crop(bbox).resize((w,h))\n",
    "\n",
    "    return np.asarray(im_sml)\n",
    "\n",
    "# augment image as 3D ndarray\n",
    "def augment(img,rng,h=224,w=224):\n",
    "    r_rotate = rng.uniform(-np.pi/6,np.pi/6,1)[0]\n",
    "    tf_rotate = tf.SimilarityTransform(rotation=r_rotate)\n",
    "    tf_scale = tf.SimilarityTransform(scale=rng.uniform(1,1.5,1))\n",
    "    tf_shear = tf.AffineTransform(shear=rng.uniform(-0.1,0.1,1))\n",
    "    tf_shift = tf.SimilarityTransform(translation=[-w/2, -h/2])\n",
    "    tf_shift_inv = tf.SimilarityTransform(translation=[w/2, h/2])\n",
    "    trans = tf_shift + tf_scale + tf_shear + tf_rotate + tf_shift_inv\n",
    "\n",
    "    img_aug = tf.warp(img, trans.inverse)\n",
    "    # randomly flip vertically\n",
    "    if rng.uniform() > 0.5:\n",
    "        img_aug = img_aug[::-1,:,:]\n",
    "    # randomly flip horizontally\n",
    "    if rng.uniform() > 0.5:\n",
    "        img_aug = img_aug[:,::-1,:]\n",
    "\n",
    "    return img_aug\n",
    "\n",
    "# scale to [0,1]\n",
    "def scale_pixels(im):\n",
    "    return im/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fpath = df.fpath.iloc[0]\n",
    "rng = np.random.RandomState(1)\n",
    "im = read_resize(fpath,rng)\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.subplot(161)\n",
    "plt.imshow(im)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "for i in range(2,7):\n",
    "    plt.subplot(1,6,i)\n",
    "    plt.imshow(augment(im,rng)) # sample augment\n",
    "    plt.title('Augmented')\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(df,rng,batch_size=64,h_out=224,w_out=224,ch_out=3):\n",
    "    \"\"\"\n",
    "    This generator produces a batch of (X,y).\n",
    "    Images are randomly augmented.\n",
    "    \n",
    "    Inputs:\n",
    "    df is a pandas dataframe containing the file path (fpath) and class (category)\n",
    "\n",
    "    Outputs:\n",
    "    X is a 4D tensor of shape (batch_size,h,w,ch)\n",
    "    y is a 2D vector of (batch_size,3), for the 3 classes\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(df)\n",
    "    total_batch = int(np.ceil(n / batch_size))\n",
    "    logging.info('generating %d batches with %d samples per epoch' % (total_batch,n))\n",
    "\n",
    "    # initialize labelBinarizer\n",
    "    ohc = LabelBinarizer()\n",
    "    ohc.fit(df.category)\n",
    "\n",
    "    while True:\n",
    "        # shuffle examples every epoch\n",
    "        df_shuffled = df.iloc[rng.permutation(n)]\n",
    "        for i_batch in range(total_batch):\n",
    "            # limit end index by size of df_gen to prevent\n",
    "            # indexing up to the next multiple of batch_size\n",
    "            i_start, i_end = i_batch * batch_size, min((i_batch + 1) * batch_size,n)\n",
    "            i_batch_size = i_end - i_start\n",
    "            X = np.zeros((i_batch_size,h_out,w_out,ch_out))\n",
    "            Y = np.zeros((i_batch_size,3))\n",
    "            for i in range(i_start,i_end):\n",
    "                fpath = df_shuffled.iloc[i]['fpath']\n",
    "                im = read_resize(fpath,rng)\n",
    "                im_aug = augment(im,rng,h=h_out,w=w_out)\n",
    "                i_intrabatch = i - i_start\n",
    "                X[i_intrabatch,...] = im_aug\n",
    "            Y = ohc.transform(df_shuffled.iloc[i_start:i_end]['category'])\n",
    "            logging.debug('yielding batch %d of size %d' % (i_batch, i_batch_size))\n",
    "            yield(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, ZeroPadding2D, Layer,\\\n",
    "    Activation, Dropout, Flatten, GlobalAveragePooling2D, GlobalMaxPooling2D, \\\n",
    "    Dense, add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# setup model\n",
    "\n",
    "# creates a residual block\n",
    "def res_block(input_layer,depth,layer_number,if_pool=True):\n",
    "    # skip bn-relu for first layer (0-indexed here)\n",
    "    if layer_number > 0:\n",
    "        bn = BatchNormalization()(input_layer)\n",
    "        bn_relu = Activation('relu')(bn)\n",
    "    else:\n",
    "        bn_relu = input_layer\n",
    "    bn_relu_conv = Conv2D(depth,(3,3),name='conv'+str(layer_number)+'_1',\n",
    "                               padding='same',kernel_regularizer=l2(0.0001))(bn_relu)\n",
    "    bn_relu_conv_bn = BatchNormalization()(bn_relu_conv)\n",
    "    bn_relu_conv_bn_relu = Activation('relu')(bn_relu_conv_bn)\n",
    "    bn_relu_conv_bn_relu_conv = Conv2D(depth,(3,3),name='conv'+str(layer_number)+'_2',\n",
    "                               padding='same',kernel_regularizer=l2(0.0001))(bn_relu_conv_bn_relu)\n",
    "    residual = Conv2D(depth,(1,1),name='resid'+str(layer_number),padding='same',\n",
    "                             kernel_regularizer=l2(0.0001))(input_layer)\n",
    "    merged = add([bn_relu_conv_bn_relu_conv,residual])\n",
    "    merged_pool = MaxPooling2D((2,2),strides=(2,2))(merged)\n",
    "    return merged_pool\n",
    "\n",
    "\n",
    "def new_model(h_in=224, w_in=224 ,ch=3):\n",
    "    \n",
    "    image_input = Input(shape=(224,224,3))\n",
    "\n",
    "    res1_out = res_block(image_input,16,0,True)\n",
    "    res2_out = res_block(res1_out,32,1,True)\n",
    "    res3_out = res_block(res2_out,64,2,True)\n",
    "    res4_out = res_block(res3_out,128,3,True)\n",
    "    res5_out = res_block(res4_out,128,4,False)\n",
    "    res6_out = res_block(res5_out,256,5,True)\n",
    "    res7_out = res_block(res6_out,512,6,False)\n",
    "    res7_avg = GlobalAveragePooling2D()(res7_out)\n",
    "    res7_max = GlobalMaxPooling2D()(res7_out)\n",
    "    post_conv_flat = concatenate([res7_avg,res7_max])\n",
    "\n",
    "    post_conv_flat = Dropout(0.2)(post_conv_flat)\n",
    "    post_conv_flat = Dense(128, activation='relu')(post_conv_flat)\n",
    "    post_conv_flat = Dropout(0.2)(post_conv_flat)\n",
    "    predictions = Dense(3, activation='softmax')(post_conv_flat)\n",
    "\n",
    "    model = Model(inputs=[image_input],outputs=[predictions])\n",
    "    return model\n",
    "\n",
    "model = new_model()\n",
    "adam = Adam(lr=0.001)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# setup tensorboard graph directory\n",
    "graph_dir = 'graph/graph_resnet'\n",
    "if not os.path.exists(graph_dir):\n",
    "    os.makedirs(graph_dir)\n",
    "\n",
    "# prepare callbacks\n",
    "tb = TensorBoard(log_dir=graph_dir, write_graph=True, write_images=True)\n",
    "mc_coord = ModelCheckpoint(filepath='models/classifier_ep{epoch:02d}_loss{val_loss:.2f}_acc{val_acc:.2f}.h5',\n",
    "                           verbose=1,save_best_only=True)\n",
    "reducelr = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=5, \n",
    "                             verbose=1, mode='min', min_delta=0.0001, cooldown=0, min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(290615)\n",
    "\n",
    "# setup epoch params\n",
    "n, batch_size = len(df), 32\n",
    "total_batch = int(np.ceil(n / batch_size))\n",
    "\n",
    "# we just use train valid test for training our model\n",
    "ix_coord = rng.choice(range(3),p=[0.8,0.1,0.1],size=len(df))\n",
    "df_train = df.ix[ix_coord==0]\n",
    "df_valid = df.ix[ix_coord==1]\n",
    "df_test = df.ix[ix_coord==2]\n",
    "gn_train = gen(df_train,rng=rng,batch_size=batch_size,h_out=224,w_out=224)\n",
    "gn_valid = gen(df_valid,rng=rng,batch_size=batch_size,h_out=224,w_out=224)\n",
    "steps_per_epoch = int(np.ceil(len(df_train) / batch_size))\n",
    "validation_steps = int(np.ceil(len(df_valid) / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "# system libraries\n",
    "import os\n",
    "from glob import glob\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "model.fit_generator(generator=gn_train,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=gn_valid,\n",
    "                    validation_steps=validation_steps,\n",
    "                    epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf; \n",
    "print(tf.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
